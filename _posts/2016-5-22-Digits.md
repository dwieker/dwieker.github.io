---
layout: post
title: Classifying Handwritten Digits
---
![](https://raw.githubusercontent.com/dwieker/dwieker.github.io/master/images/Screenshot%20from%202016-05-22%2009%3A21%3A30.png)

For our third project at metis, my group and I tried our hand at handwritten digit classification. More specifically, given a scan or image of a page full of digits, locate and classify each inidivdual digit on the page. 

The classic (MNIST data set)[http://yann.lecun.com/exdb/mnist/] provides a set of 60k images to train and test our machine learning algorithms on. Initially, I tried breaking each image into a set of about 10 features -- including things like mean horizontal/vertical position of pixels, symmetry, total size, radial moment of intertia, and average number of edges when treversing from left to right and down to up. With these set of features, all the classic classification algorithms could be applied. We tried Logistic Regression, Support Vector Machine and Naive bayes, but ultimately Random forrest gave the best result: 91% of the MNIST test data could be accurately identified. 

91% isn't enough to be very USEFUL. Given an image of digits, the resulting text scan would be full of typos and hardly worthwhile. So we shifted to a new method -- (Convolutional Neural Networks.)[https://en.wikipedia.org/wiki/Convolutional_neural_network]


![](https://raw.githubusercontent.com/dwieker/dwieker.github.io/master/images/Screenshot%20from%202016-05-22%2009%3A20%3A01.png)



![](https://raw.githubusercontent.com/dwieker/dwieker.github.io/master/images/Screenshot%20from%202016-05-22%2009%3A21%3A04.png)



![](https://raw.githubusercontent.com/dwieker/dwieker.github.io/master/images/Screenshot%20from%202016-05-22%2009%3A21%3A46.png)
