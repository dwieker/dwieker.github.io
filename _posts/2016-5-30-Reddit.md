---
layout: post
title: Subreddit Clustering
---

<iframe src="https://vida.io/gists/vn2hn29qg8H6a6DwN/index.html" seamless frameborder="0" width="808" height="816"></iframe>

[Reddit](http://www.reddit.com) is a massive news and entertainment site driven purely by user submitted content. To keep posts thematically organized, the website is paritioned into "subreddits", which are essentially forums with a specific purpose or topic. For example, there's gaming subreddits, sports subreddits, tv show subreddits, and a subreddit for almost anything else you can think of. 

As of now, there's no fast and easy way to discover new subreddits pertaining to your own interests. People share subreddits amongst each other, and occasionally you'll stumble across one you like, but for some reason there's no form of subbreddit *recommendation*.

Thus, I was inspired to create a simple, personalized recommendation service that generates relevant subreddits from a user's reddit data. Specifically, every user has a publically viewable comment history that contains the time, content and parent-subreddit of every comment they've ever posted. If a user is fairly active on the site, you can use this data to profile their interests incredibly well -- and thus use this "interest profile" to suggest subreddits they're likely to be interested in.

To map a user's comment data to relevant subreddits, it would useful to create a measure of subreddit simularity. Given a sub X, find what subs Y most resemble X. For example, given some subreddit focused on an RPG game, spit out subreddits that focus on other similar RPG games. 

To accomplish this, I started by collecting over 20 million reddit comments. These were loaded onto an amazon mySQL database for querying. Now, to acheive a rough measure of subreddit to subreddit simularity, you might simply compare word frequencies. Strip away common words like "the", "I", "a", etc., and compare the frequency of words that are left. Subs that share many of the same words are likley to be similar to each other.

This quick method works, but not very **well**. The main pitfall is the inability to handle synonyms. There might be multiple sentences describing a singular concept, all of which a human would recgnize as referring to the same central idea, but the algorithm would assume no simalirity between the descriptions since they don't share exact words.

Fortunately, data science comes to the rescue. Enter [Latent Semantic Indexing](https://en.wikipedia.org/wiki/Latent_semantic_analysis). LSA is a ~~gift from the math gods~~ dimensionality reduction tenchinque that can reduce a set of words into a smaller set of components which represent core concepts of the text. It handles the aforementioned synonym difficulty by observing the **context** in which a word appears; "car" and "automobile" will appear in similar contexts, for example, so both words will be recognized as belonging to the same underlying concept. 

Applying LSA to the reddit comment data greatly improved my topic clustering. So much so, I decided to make a vizualization. Even after mapping the original data all the way down 2 dimensions, it still retained a surprising amount of information.  

The above plot shows the similarity between over 4000 popular subreddits. Click the icons in the bottom left to enable panning and zooming. Hover over a bubble to see the name of the subreddit.  Subreddits that are closer together are "more similar". Larger bubbles represent more active subreddits. 

*** 


