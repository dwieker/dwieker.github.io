---
layout: post
title: Subreddit Clustering
---

<iframe src="https://vida.io/gists/vn2hn29qg8H6a6DwN/index.html" seamless frameborder="0" width="808" height="816"></iframe>

[Reddit](http://www.reddit.com) is a massive news and entertainment site driven purely by user submitted content. To keep posts thematically organized, the website is paritioned into "subreddits", which are essentially forums with a specific purpose or topic. For example, there's gaming subreddits, sports subreddits, tv show subreddits, and a subreddit for almost anything else you can think of. 

As of now, there's no fast and easy way to discover new subreddits pertaining to your own interests. People share subreddits amongst each other, and occasionally you'll stumble across one you like, but for some reason there's no form of subbreddit *recommendation*.

Thus, I was inspired to create a simple, personalized recommendation service that generates relevant subreddits from a user's reddit data. Specifically, every user has a publically viewable comment history that contains the time, content and parent-subreddit of every comment they've ever posted. If a user is fairly active on the site, you can use this data to profile their interests incredibly well -- and thus use this "interest profile" to suggest subreddits they're likely to be interested in.

To map a user's comment data to relevant subreddits, it would useful to create a measure of subreddit simularity. Given a sub X, find what subs Y most resemble X. For example, given some subreddit focused on an RPG game, spit out subreddits that focus on other similar RPG games. Or given some subreddit focused on, say, nature photos, suggest other nature and photo subs.

To accomplish this, I started by collecting over 20 million reddit comments from thousands of random subreddits. Much of this data was found in some [data dump](https://www.reddit.com/r/datasets/comments/3bxlg7/i_have_every_publicly_available_reddit_comment); the rest was collected using reddit's api. The comment data was then cleaned and loaded onto an amazon mySQL database for querying. Now, to acheive a rough measure of subreddit to subreddit simularity, you might simply compare word frequencies between subreddits. Strip away common words like "the", "I", "a", etc., and compare the frequency of unique words that are left. Intuitively, Subs with comments that share many of the same words are probably similar to each other.

This quick method works, but not very **well**. The main pitfall is the inability to handle synonyms. One comment might talk about cars, another might talk about a specific car, and another might take about automobiles in general. They're all refering to a simlar idea, and should certainly be considered similar by an ideal algorithm, but a simple word to word comparison would return no similarity between them since they don't share exact words. 

Fortunately, data science comes to the rescue. Enter [Latent Semantic Indexing](https://en.wikipedia.org/wiki/Latent_semantic_analysis). LSA is a ~~gift from the math gods~~ dimensionality reduction tenchinque that can reduce a set of words into a smaller set of components which represent core concepts of the text. It handles the aforementioned synonym difficulty by observing the **context** in which a word appears; "car" and "automobile" will appear in similar contexts, for example, so both words will be recognized as belonging to the same underlying concept. 

Applying LSA to the reddit comment data greatly improved my topic clustering. So much so, I decided to make a vizualization. Even after mapping the original data all the way down 2 dimensions, it still retained a surprising amount of information.  

The above plot shows the similarity between over 4000 popular subreddits. Click the icons in the bottom left to enable panning and zooming. Hover over a bubble to see the name of the subreddit.  Subreddits that are closer together are "more similar". Larger bubbles represent more active subreddits. 

*** 


